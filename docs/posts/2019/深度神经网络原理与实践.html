<!doctype html><html class="" data-reactroot=""><head><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous"/>
<meta data-react-helmet="true" charset="utf-8"/><meta data-react-helmet="true" http-equiv="x-ua-compatible" content="ie=edge"/><meta data-react-helmet="true" name="description" content="前端工程师，爱折腾，擅长 JavaScript，欢迎关注我的公众号「自然醒的笔记本」"/><meta data-react-helmet="true" name="viewport" content="width=device-width, initial-scale=1"/><meta data-react-helmet="true" property="og:title" content="深度神经网络原理与实践 · 自然醒的博客"/><meta data-react-helmet="true" property="og:description" content="前端工程师，爱折腾，擅长 JavaScript，欢迎关注我的公众号「自然醒的笔记本」"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" name="twitter:card" content="summary"/>
<title data-react-helmet="true">深度神经网络原理与实践 · 自然醒的博客</title>
<link data-react-helmet="true" rel="stylesheet" href="/docs/assets/index.css"/><link data-react-helmet="true" id="prismTheme" rel="stylesheet" href="/docs/assets/prism.css"/>
<script data-react-helmet="true" >
    const shouldSetIsDark = document.cookie.includes('is_dark=1') ? true : document.cookie.includes('is_dark=0') ? false : window.matchMedia('(prefers-color-scheme: dark)').matches;
    if (shouldSetIsDark) {
      document.documentElement.classList.add('is_dark');
      document.getElementById('prismTheme').href = "/docs/assets/prism_tomorrow.css";
    }
  </script>
</head><body><a class="czs-menu-l show_on_mobile aside_button_open" href="#" style="background-image:url(&quot;/docs/assets/czs-menu-l.svg&quot;)"></a><a class="show_on_mobile aside_button_text" href="/docs/">自然醒的博客</a><aside class="hide_on_mobile"><div class="aside_card"><a class="czs-menu-l show_on_mobile aside_button_close" href="#" style="background-image:url(&quot;/docs/assets/czs-close-l.svg&quot;)"></a><h1><a href="/docs/">自然醒的博客</a></h1><p class="description">前端工程师，爱折腾，擅长 JavaScript，欢迎关注我的公众号「自然醒的笔记本」</p><ul class="social list_style_none"><li class="flex_center"><a class="czs-github-logo" href="https://github.com/Shenfq" target="_blank" style="background-image:url(&quot;/docs/assets/czs-github-logo.svg&quot;)"></a></li><li class="flex_center"><a class="czs-message-l" href="mailto:shenfq95@foxmail.com" target="_blank" style="background-image:url(&quot;/docs/assets/czs-message-l.svg&quot;)"></a></li><li style="flex-grow:1"></li><li class="toggle_dark flex_center"><span class="czs-sun" style="background-image:url(&quot;/docs/assets/czs-sun.svg&quot;)"></span><span class="czs-sun-l" style="background-image:url(&quot;/docs/assets/czs-sun-l.svg&quot;)"></span><span class="czs-moon" style="background-image:url(&quot;/docs/assets/czs-moon.svg&quot;)"></span><span class="czs-moon-l" style="background-image:url(&quot;/docs/assets/czs-moon-l.svg&quot;)"></span></li></ul><nav><ul class="menu list_style_none"><li><a class="flex_center" href="/"><span class="czs-home-l" style="background-image:url(&quot;/docs/assets/czs-home-l.svg&quot;)"></span>首页</a></li><li><a class="flex_center" href="/categories/"><span class="czs-category-l" style="background-image:url(&quot;/docs/assets/czs-category-l.svg&quot;)"></span>分类</a></li><li><a class="flex_center" href="/tags/"><span class="czs-tag-l" style="background-image:url(&quot;/docs/assets/czs-tag-l.svg&quot;)"></span>标签</a></li><li><a class="flex_center" href="/about/"><span class="czs-about-l" style="background-image:url(&quot;/docs/assets/czs-about-l.svg&quot;)"></span>关于</a></li><li><a class="flex_center" href="/archives/"><span class="czs-box-l" style="background-image:url(&quot;/docs/assets/czs-box-l.svg&quot;)"></span>归档</a></li><li><a class="flex_center" href="/links/index.html"><span class="czs-link-l" style="background-image:url(&quot;/docs/assets/czs-link-l.svg&quot;)"></span>友情链接</a></li></ul></nav></div><nav class="toc"><ol><li><a href="#%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80">理论基础</a><ol><li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">什么是神经网络</a></li><li><a href="#%E7%A5%9E%E7%BB%8F%E5%85%83%E5%A6%82%E4%BD%95%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA">神经元如何输入输出</a><ol></ol></li><li><a href="#%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95">矩阵乘法</a><ol></ol></li><li><a href="#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD">反向传播</a><ol></ol></li><li><a href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D">梯度下降</a></li></ol></li><li><a href="#%E5%AE%9E%E6%88%98">实战</a><ol><li><a href="#%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87">环境准备</a><ol></ol></li><li><a href="#%E6%90%AD%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">搭建神经网络</a><ol></ol></li><li><a href="#%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83">进行训练</a></li><li><a href="#%E9%AA%8C%E8%AF%81%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C">验证训练结果</a></li><li><a href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81">完整代码</a></li></ol></li><li><a href="#%E6%80%BB%E7%BB%93">总结</a></li></ol></nav></aside><section class="main"><h1>深度神经网络原理与实践</h1><div class="main_post_meta"><time dateTime="2019/03/17">2019-03-17</time> · <!-- -->shenfq</div><article><h2 id="%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80">理论基础<a class="anchor" href="#%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80">§</a></h2>
<h3 id="%E4%BB%80%E4%B9%88%E6%98%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">什么是神经网络<a class="anchor" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">§</a></h3>
<p>我们知道深度学习是机器学习的一个分支，是一种以人工神经网络为架构，对数据进行表征学习的算法。而深度神经网络又是深度学习的一个分支，它在 wikipedia 上的解释如下：</p>
<blockquote>
<p>深度神经网络（Deep Neural Networks, DNN）是一种判别模型，具备至少一个隐层的神经网络，可以使用反向传播算法进行训练。权重更新可以使用下式进行随机梯度下降法求解。</p>
</blockquote>
<p>首先我们可以知道，深度神经网络是一种判别模型。意思就是已知变量 x ，通过判别模型可以推算出 y。比如机器学习中常用到的案例，通过手写数字，模型推断出手写的是数字几。</p>
<p><img src="https://file.shenfq.com/Fjw7fiWg-n1qXji4aX9DUz10Nrqa.png" alt="image"></p>
<p>深度神经网络中的“深度”指的是一系列连续的表示层，数据模型中包含了多少层，这就被称为模型的“深度”。通过这些层我们可以对数据进行高层的抽象。如下图所示，深度神级网络由一个输入层，多个（至少一个）隐层，以及一个输出层构成，而且输入层与输出层的数量不一定是对等的。每一层都有若干个神经元，神经元之间有连接权重。</p>
<p><img src="https://file.shenfq.com/FuBpmY1q3QeBX22BvqjMUV2ea1U0.png" alt="image"></p>
<p>还是上面的案例，识别手写数字，手写的数字要怎么转成输入呢？既然是手写，那么肯定是一张图片，图片由多个像素点组成，这些像素点可以构成一个输入，经过多层神经网络，输出10个数字，这个10个数字就代表了数字 0 ~ 9 的概率。</p>
<p><img src="https://file.shenfq.com/FsdJBzIsxftYo9e89lUwU2wlx5O7.png" alt="image"></p>
<h3 id="%E7%A5%9E%E7%BB%8F%E5%85%83%E5%A6%82%E4%BD%95%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA">神经元如何输入输出<a class="anchor" href="#%E7%A5%9E%E7%BB%8F%E5%85%83%E5%A6%82%E4%BD%95%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA">§</a></h3>
<p>神经网络中的每个神经元都可以看成是一个简单的线性函数，下面我们构造一个简单的三层的神经网络来看看。</p>
<p><img src="https://file.shenfq.com/FnQlw8WyQxZ-iszYHdFur7PxwrY0.png" alt="image"></p>
<p>如上图所示，n1 可以表示为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>=</mo><msub><mi>w</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mrow><mn>2</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><msub><mi>w</mi><mrow><mn>3</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub><msub><mi>x</mi><mn>3</mn></msub><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">n_1 = w_{1,1}x_1 + w_{2,1}x_2 + w_{3,1}x_3 + b
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8694379999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8694379999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8694379999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">w_{1,1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 表示神经元之间的权重，b 为一个常量，作为函数的偏移量。较小的权重可以弱化某个神经元对下一个神经元造成的影响，而较大的权重将放大信号。假设 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">w_{1,1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 为 0.1，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mn>3</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">w_{3,1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 为 0.7，那么 x3 对 n1 的影响要大于 x1。你可能会问，为什么每个神经元要与其他所有层的神经元相互连接？</p>
<p>这里主要由两个原因：</p>
<ol>
<li>完全连接的形式相对容易的编写成计算机指令。</li>
<li>在神经网络训练的过程中会弱化实际上不需要的连接（也就是某些连接权重会慢慢趋近于 0）。</li>
</ol>
<p>实际上通过计算得到 n1 后，其实不能立马用于后面的计算，还需要经过一个激活函数（一般为 sigmod 函数）。</p>
<p><img src="https://file.shenfq.com/Fvu_bZlZ1vUg249qL6Rjvox19GXg.png" alt="image"></p>
<p><img src="https://file.shenfq.com/Ft059zilmQAlgRWVCl56_DV_MjoB.png" alt="sigmod 函数"></p>
<p>其作用主要是引入非线性因素。如果神级网络中只有上面那种线性函数，无论有多少层，结果始终是线性的。</p>
<h4 id="%E5%AE%9E%E9%99%85%E6%A1%88%E4%BE%8B">实际案例<a class="anchor" href="#%E5%AE%9E%E9%99%85%E6%A1%88%E4%BE%8B">§</a></h4>
<p>为了方便计算，我们构造一个只有两层的神经网络，演示一下具体的计算过程。</p>
<p><img src="https://file.shenfq.com/FozUDE0MOGnnoMqGhIOzVlFekc-k.png" alt="image"></p>
<p>先通过线性函数求得一个 x 值，再把 x 值带入激活函数，得到 y1 的值。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>x</mi><mo>=</mo><msub><mi>w</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mrow><mn>2</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub><msub><mi>x</mi><mn>2</mn></msub><mo>=</mo><mo stretchy="false">(</mo><mn>1.0</mn><mo>∗</mo><mn>0.9</mn><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>0.5</mn><mo>∗</mo><mn>0.3</mn><mo stretchy="false">)</mo><mo>=</mo><mn>1.05</mn></mrow><annotation encoding="application/x-tex">x = w_{1,1}x_1 + w_{2,1}x_2 = (1.0 * 0.9) + (0.5 * 0.3) = 1.05
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8694379999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mord">.</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">3</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">0</span><span class="mord">5</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>=</mo><mn>1</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mn>0.3499</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0.7408</mn></mrow><annotation encoding="application/x-tex">y_1 = 1 / (1 + e ^{-x}) = 1 / (1 + 0.3499) = 0.7408
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mord">/</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.071331em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.821331em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mord">/</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">3</span><span class="mord">4</span><span class="mord">9</span><span class="mord">9</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">7</span><span class="mord">4</span><span class="mord">0</span><span class="mord">8</span></span></span></span></span></p>
<h3 id="%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95">矩阵乘法<a class="anchor" href="#%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95">§</a></h3>
<p>其实上面的计算过程，很容易通过矩阵乘法的方式表示。矩阵这个东西，说简单点就是一个表格，或者一个二维数组。如下图所示，就是一个典型的矩阵。</p>
<p><img src="https://file.shenfq.com/Fle6c7tCJeSpI56GXYLhpDvI5F9o.png" alt="image"></p>
<p>那么矩阵的乘法可以表示为：</p>
<p><img src="https://file.shenfq.com/Fl5i9c6pmYwtkwupgDlppqaA-YsD.png" alt="image"></p>
<p>矩阵的乘法通常被成为点乘或者内积。如果我们将矩阵内的数字换成我们神经网络的输入和权重，你会发现原来前面的计算如此简单。</p>
<p><img src="https://file.shenfq.com/FvkpHJlq3aCNMqw-plANUCRp3_r-.png" alt="image"></p>
<p>获得点积后，只需要代入到激活函数，就能获得输出了。</p>
<p><img src="https://file.shenfq.com/Fh7GrdgN0p0Y0Ys5qrcQUxdqVx3N.png" alt="image"></p>
<p>通过矩阵计算过程可以表示为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>X</mi><mrow><mi>h</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi></mrow></msub><mo>=</mo><msub><mi>W</mi><mrow><mi>i</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>h</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi></mrow></msub><mo separator="true">⋅</mo><msub><mi>I</mi><mrow><mi>i</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi></mrow></msub><msub><mi>O</mi><mrow><mi>h</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi></mrow></msub><mo>=</mo><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>o</mi><mi>i</mi><mi>d</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mrow><mi>h</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">X_{hidden} = W_{input\_hidden} · I_{input}

O_{hidden} = sigmoid(X_{hidden})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.05033em;vertical-align:-0.367em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.367em;"><span></span></span></span></span></span></span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<h4 id="%E5%AE%9E%E9%99%85%E6%A1%88%E4%BE%8B-1">实际案例<a class="anchor" href="#%E5%AE%9E%E9%99%85%E6%A1%88%E4%BE%8B-1">§</a></h4>
<p>下面通过矩阵来表示一个三层神经网络的计算过程。</p>
<p><img src="https://file.shenfq.com/Fipyv33DnVPnwP-GY55JevCWbFOk.png" alt="image"></p>
<p>上图只给出了输入层到隐层的计算过程，感兴趣可以自己手动计算下，隐层到输出层的计算过程。隐层到输出层的权重矩阵如下：</p>
<p><img src="https://file.shenfq.com/FlAAJfkpy5sVbAfRcFh5SC084ufW.png" alt="image"></p>
<h3 id="%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD">反向传播<a class="anchor" href="#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD">§</a></h3>
<p>进过一轮神经网络计算得到输出值，通常与我们实际想要的值是不一致的，这个时候我们会得到一个误差值（误差值就是训练数据给出的正确答案与实际输出值之间的差值）。但是这个误差是多个节点共同作用的结果，我们到底该用何种方式来更新各个连接的权重呢？这个时候我们就需要通过反向传播的方式，求出各个节点的误差值。</p>
<p><img src="https://file.shenfq.com/Fs3p0gufO8D59AXgizAwXk4VI3vU.png" alt="image"></p>
<p>下面我们代入具体值，进行一次计算。</p>
<p><img src="https://file.shenfq.com/Fn2bljmwTC0IIqdAldaMKpv-WQ5N.png" alt="image"></p>
<p>上图中可以看到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">e_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的误差值主要由 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">w_{1,1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mn>2</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">w_{2,1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 造成，那么其误差应当分散到两个连接上，可以按照两个连接的权重对误差 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">e_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 进行分割。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>e</mi><mn>1</mn></msub><mo>∗</mo><mfrac><msub><mi>w</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub><mrow><msub><mi>w</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>w</mi><mrow><mn>2</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub></mrow></mfrac><mo>=</mo><mn>0.8</mn><mo>∗</mo><mfrac><mn>2</mn><mrow><mn>2</mn><mo>+</mo><mn>3</mn></mrow></mfrac><mo>=</mo><mn>0.32</mn></mrow><annotation encoding="application/x-tex">e_1 * \frac{w_{1,1}}{w_{1,1} + w_{2,1}} = 0.8 * \frac{2}{2 + 3} = 0.32
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61528em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.079668em;vertical-align:-0.972108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.972108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.09077em;vertical-align:-0.7693300000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">3</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693300000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">3</span><span class="mord">2</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>e</mi><mn>1</mn></msub><mo>∗</mo><mfrac><msub><mi>w</mi><mrow><mn>2</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub><mrow><msub><mi>w</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>w</mi><mrow><mn>2</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub></mrow></mfrac><mo>=</mo><mn>0.8</mn><mo>∗</mo><mfrac><mn>3</mn><mrow><mn>2</mn><mo>+</mo><mn>3</mn></mrow></mfrac><mo>=</mo><mn>0.48</mn></mrow><annotation encoding="application/x-tex">e_1 * \frac{w_{2,1}}{w_{1,1} + w_{2,1}} = 0.8 * \frac{3}{2 + 3} = 0.48
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61528em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.079668em;vertical-align:-0.972108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.972108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.09077em;vertical-align:-0.7693300000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">3</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693300000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">4</span><span class="mord">8</span></span></span></span></span></p>
<p>同理对误差 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">e_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 进行分割，然后把两个连接处的误差值相加，就能得到输出点的前馈节点的误差值。</p>
<p><img src="https://file.shenfq.com/FrCafEfslODTYVqrV6pFZaMI-TiG.png" alt="image"></p>
<p>然后在按照之前的方法将这个误差传播到前面的层，直到所有节点都能得到自己的误差值，这种方式被成为反向传播。</p>
<h4 id="%E4%BD%BF%E7%94%A8%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E8%BF%9B%E8%A1%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E8%AF%AF%E5%B7%AE">使用矩阵乘法进行反向传播误差<a class="anchor" href="#%E4%BD%BF%E7%94%A8%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E8%BF%9B%E8%A1%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E8%AF%AF%E5%B7%AE">§</a></h4>
<p>上面如此繁琐的操作，我们也可以通过矩阵的方式进行简化。</p>
<p><img src="https://file.shenfq.com/FmYWgu8b1lMgQxEqynXOxxllgaYa.png" alt="image"></p>
<p>这个矩阵中还是有麻烦的分数需要处理，那么我们能不能大胆一点，将分母直接做归一化的处理。这么做我们仅仅只是改变了反馈误差的大小，其误差依旧是按照比例来计算的。</p>
<p><img src="https://file.shenfq.com/FjD8lHUXF7Ytn9W8YWcnHOUa28-9.png" alt="image"></p>
<p><img src="https://file.shenfq.com/FmdzXGU-rU3BCo-Mz3eNvKckP-wE.png" alt="image"></p>
<p>仔细观察会发现，与我们之前计算每层的输出值的矩阵点击很像，只是权重矩阵进行翻转，右上方的元素变成了左下方的元素，我们可以称其为转置矩阵，记为 $ w^T $。</p>
<p>反向传播误差的矩阵可以简单表示为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>e</mi><mi>r</mi><mi>r</mi><mi>o</mi><msub><mi>r</mi><mrow><mi>h</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi></mrow></msub><mo>=</mo><msubsup><mi>W</mi><mrow><mi>h</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi></mrow><mi>T</mi></msubsup><mo separator="true">⋅</mo><mi>e</mi><mi>r</mi><mi>r</mi><mi>o</mi><msub><mi>r</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">error_{hidden} = W^{T}_{hidden\_output} · error_{output}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.355331em;vertical-align:-0.46399999999999997em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.891331em;"><span style="top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46399999999999997em;"><span></span></span></span></span></span></span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.28055599999999997em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<h3 id="%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D">梯度下降<a class="anchor" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D">§</a></h3>
<p>在每个点都得到误差后，我们该按照何种方式来更新权重呢？</p>
<p>这个时候就要使用到机器学习中常用的方式：梯度下级。</p>
<p><img src="https://file.shenfq.com/FsrJBt8QxtpMcJ2qpJeeTAR0sYTW.png" alt="image"></p>
<p>更多细节可以参考我之前写的博客：<a href="https://blog.shenfq.com/2019/01/28/2019/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B8%8E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">梯度下降与线性回归</a></p>
<p>通过不停的训练，我们就能改进神经网络，其本质就是不断地改变权重的大小，减小神经网络输出的误差值。
最后就能够得到一个多层神经网络的模型，通过输入进行有效的预测。</p>
<h2 id="%E5%AE%9E%E6%88%98">实战<a class="anchor" href="#%E5%AE%9E%E6%88%98">§</a></h2>
<h3 id="%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87">环境准备<a class="anchor" href="#%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87">§</a></h3>
<p>首先需要安装 python3 ，直接去 python 官网安装，尽量安装最新版，不推荐安装 python2 。安装好 python 环境之后，然后安装 virtualenv 以及相关依赖。</p>
<pre class="language-bash"><code class="language-bash"><span class="token comment"># 升级 pip 到最新版本</span>
pip3 <span class="token function">install</span> --upgrade pip

<span class="token comment"># 安装 virtualenv ，用于配置虚拟环境</span>
pip3 <span class="token function">install</span> --user --upgrade virtualenv
</code></pre>
<p>正常情况下，当我们在使用 pip 进行包安装的时候，都是安装的全局包，相当于<code>npm install -g</code>。假如现在有两个项目，项目 A 依赖 simplejson@2 ，项目 B 依赖 simplejson@3，这样我们在一台机器上开发显得有些手足无措。这个时候 virtualenv 就能大展身手了，virtualenv 可以创建一个独立的 python 运行环境，也就是一个沙箱，你甚至可以在 virtualenv 创建的虚拟环境中使用与当前系统不同的 python 版本。</p>
<pre class="language-bash"><code class="language-bash"><span class="token comment"># 配置虚拟环境</span>
<span class="token builtin class-name">cd</span> ~/ml
virtualenv <span class="token function">env</span>

<span class="token comment"># 启动虚拟环境</span>
<span class="token comment"># linux</span>
<span class="token builtin class-name">source</span> env/bin/activate
<span class="token comment"># windows</span>
./env/Scripts/activate

</code></pre>
<p>启动后，如下</p>
<pre class="language-bash"><code class="language-bash"><span class="token punctuation">(</span>env<span class="token punctuation">)</span> λ 
</code></pre>
<p><img src="https://file.shenfq.com/Fn5PT4ZTWJRwwnOIMTRAP6AZV07z.png" alt="image"></p>
<p>在虚拟环境下安装所有模块依赖。</p>
<pre class="language-bash"><code class="language-bash"><span class="token comment"># 安装模块和依赖</span>
<span class="token punctuation">(</span>env<span class="token punctuation">)</span> λ pip3 <span class="token function">install</span> --upgrade jupyter matplotlib numpy scipy
</code></pre>
<ul>
<li>
<p>jupyter：基于网页的用于交互计算的应用程序。其可被应用于全过程计算：开发、文档编写、运行代码和展示结果。</p>
</li>
<li>
<p>numpy：数组计算扩展的包，支持高维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。</p>
</li>
<li>
<p>scipy：基于numpy的扩展包，它增加的功能包括数值积分、最优化、统计和一些专用函数。</p>
</li>
<li>
<p>matplotlib：基于numpy的扩展包，提供了丰富的数据绘图工具，主要用于绘制一些统计图形。</p>
</li>
<li>
<p>scikit-learn：开源的Python机器学习库，它基于Numpy和Scipy，提供了大量用于数据挖掘和分析的工具，包括数据预处理、交叉验证、算法与可视化算法等一系列接口。</p>
</li>
</ul>
<h4 id="%E5%90%AF%E5%8A%A8-jupyter">启动 jupyter<a class="anchor" href="#%E5%90%AF%E5%8A%A8-jupyter">§</a></h4>
<pre class="language-autoit"><code class="language-autoit">jupyter notebook
</code></pre>
<p>jupyter 会在8888端口起一个服务，并自动打开浏览器。</p>
<p><img src="https://file.shenfq.com/FoIVlLx4Rsh81RLyGmgZ5r0lyuZe.png" alt="image"></p>
<p>通过右上角的new，你就能创建一个项目了。创建项目后，我们很方便的在该页面上进行 python 代码的运行与输出。</p>
<p><img src="https://file.shenfq.com/FmSvJC2Uv_plGVynXbzcWsNfeyEV.gif" alt="image"></p>
<h4 id="%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE">准备数据<a class="anchor" href="#%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE">§</a></h4>
<p>MNIST 是由美国的高中生和美国人口调查局的职员手写数字（0 ~ 9）图片。接下来要做的事情就是让我们的程序学习这些图片的信息，能够识别出输入的图片所代表的数字含义，这听上去好像有点难度，不着急，我们一步步来。</p>
<p>这里准备了 MNIST 的训练数据，其中 <code>train_100</code> 为训练数据集，<code>test_10</code> 为测试数据集。在机器学习的过程中，我们一般会将数据集切分成两个，分别为训练集合测试集，一般 80% 的数据进行训练，保留 20% 用于测试。这里因为是 hello world 操作，我们只用 100 个数据进行训练，真实情况下，这种数据量是远远不够的。</p>
<ul>
<li><a href="https://raw.githubusercontent.com/makeyourownneuralnetwork/makeyourownneuralnetwork/master/mnist_dataset/mnist_train_100.csv">mnist_train_100.csv</a></li>
<li><a href="https://raw.githubusercontent.com/makeyourownneuralnetwork/makeyourownneuralnetwork/master/mnist_dataset/mnist_test_10.csv">mnist_test_10.csv</a></li>
</ul>
<p>如果想用完整的数据进行训练，可以下载这个 csv 文件。</p>
<p><a href="https://pjreddie.com/media/files/mnist_train.csv">https://pjreddie.com/media/files/mnist_train.csv</a></p>
<h4 id="%E8%A7%82%E5%AF%9F%E6%95%B0%E6%8D%AE">观察数据<a class="anchor" href="#%E8%A7%82%E5%AF%9F%E6%95%B0%E6%8D%AE">§</a></h4>
<p>下载数据后，将 csv （逗号分隔值文件格式）文件放入到 datasets 文件夹，然后使用 python 进行文件的读取。</p>
<pre class="language-python"><code class="language-python">data_file <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"datasets/mnist_train_100.csv"</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>
data_list <span class="token operator">=</span> data_file<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># readlines方法用于读取文件的所有行，并返回一个数组</span>
data_file<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token builtin">len</span><span class="token punctuation">(</span>data_list<span class="token punctuation">)</span> <span class="token comment"># 数组长度为100</span>
</code></pre>
<p>打印第一行文本，看看数据的格式是怎么样的</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>data_list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token builtin">len</span><span class="token punctuation">(</span>data_list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 使用 , 进行分割，将字符串转换为数组</span>
</code></pre>
<p><img src="https://file.shenfq.com/FpwLohSBEtk8nhG2dyGeE91jZwHe.png" alt="image"></p>
<p>可以看到一行数据一共有 785 个数据，第一列表示这个手写数的真实值（这个值在机器学习中称为标签），后面的 784 个数据表示一个 28 * 28 的尺寸的像素值，流行的图像处理软件通常用8位表示一个像素，这样总共有256个灰度等级(像素值在0~255 间)，每个等级代表不同的亮度。</p>
<p>下面我们导入 numpy 库，对数据进行处理，values[1:] 取出数组的第一位到最后并生成一个新的数组，使用 numpy.asfarray 将数组转为一个浮点类型的 ndarray，然后每一项除以 255 在乘以 9，将每个数字转为 0 ~ 9 的个位数，使用 astype(int) 把每个数再转为 int 类型，最后 reshape((28,28) 可以把数组转为 28 * 28 的二维数组。</p>
<p>如果想了解更多 numpy 的资料，可以查看它的<a href="https://www.numpy.org.cn/index.html">文档</a>。</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

values <span class="token operator">=</span> data_list<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span>
image_array <span class="token operator">=</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>asfarray<span class="token punctuation">(</span>values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span> <span class="token operator">*</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span>
</code></pre>
<p><img src="https://file.shenfq.com/FrwDGzwLUk0yEgKOvPPRCykAOJWg.png" alt="image"></p>
<p>这样看不够直观，接下来使用 matplotlib ，将像素点一个个画出来。</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot
<span class="token operator">%</span>matplotlib inline

matplotlib<span class="token punctuation">.</span>pyplot<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>
    np<span class="token punctuation">.</span>asfarray<span class="token punctuation">(</span>values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    cmap<span class="token operator">=</span><span class="token string">'Greys'</span><span class="token punctuation">,</span> 
    interpolation<span class="token operator">=</span><span class="token string">'None'</span>
<span class="token punctuation">)</span>
</code></pre>
<p><img src="https://file.shenfq.com/FjeF-u3KhHB0ii7ryTNiR1Aji28v.png" alt="image"></p>
<h3 id="%E6%90%AD%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">搭建神经网络<a class="anchor" href="#%E6%90%AD%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">§</a></h3>
<p>我们简单勾勒出神经网络的大概样子，至少需要三个函数：</p>
<ol>
<li>初始化函数——设定输入层、隐藏层、输出层节点的数量，随机生成的权重。</li>
<li>训练——学习给定的训练样本，调整权重。</li>
<li>查询——给定输入，获取预测结果。</li>
</ol>
<p>框架代码如下：</p>
<pre class="language-python"><code class="language-python"><span class="token comment"># 引入依赖库</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> scipy<span class="token punctuation">.</span>special
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot

<span class="token comment"># 神经网络类定义</span>
<span class="token keyword">class</span> <span class="token class-name">neuralNetwork</span><span class="token punctuation">:</span>
    <span class="token comment"># 初始化神经网络</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>

    <span class="token comment"># 训练神经网络</span>
    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
   
    <span class="token comment"># 查询神经网络</span>
    <span class="token keyword">def</span> <span class="token function">query</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
</code></pre>
<h4 id="%E5%88%9D%E5%A7%8B%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">初始化神经网络<a class="anchor" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">§</a></h4>
<p>接下来让我们进行第一步操作，初始化一个神经网络。</p>
<pre class="language-python"><code class="language-python">    <span class="token comment"># 初始化神经网络</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputnodes<span class="token punctuation">,</span> hiddennodes<span class="token punctuation">,</span> outputnodes<span class="token punctuation">,</span> learningrate<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 设置输入层、隐藏层、输出层节点的数量</span>
        self<span class="token punctuation">.</span>inodes <span class="token operator">=</span> inputnodes
        self<span class="token punctuation">.</span>hnodes <span class="token operator">=</span> hiddennodes
        self<span class="token punctuation">.</span>onodes <span class="token operator">=</span> outputnodes
        
        <span class="token comment"># 连接权重，随机生成输入层到隐藏层和隐藏层到输出层的权重</span>
        self<span class="token punctuation">.</span>wih <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hnodes<span class="token punctuation">,</span> self<span class="token punctuation">.</span>inodes<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">0.5</span>
        self<span class="token punctuation">.</span>who <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>self<span class="token punctuation">.</span>onodes<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hnodes<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">0.5</span>

        <span class="token comment"># 学习率</span>
        self<span class="token punctuation">.</span>lr <span class="token operator">=</span> learningrate
        
        <span class="token comment"># 将激活函数设置为 sigmoid 函数</span>
        self<span class="token punctuation">.</span>activation_function <span class="token operator">=</span> <span class="token keyword">lambda</span> x<span class="token punctuation">:</span> scipy<span class="token punctuation">.</span>special<span class="token punctuation">.</span>expit<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        
        <span class="token keyword">pass</span>
</code></pre>
<p><strong>生成权重</strong></p>
<p>生成连接权重使用 <code>numpy</code> 函数库，该库支持大维度数组以及矩阵的运算，通过<code>numpy.random.rand(x, y)</code>可以快速生成一个 <code>x * y</code> 的矩阵，每个数字都是一个 0 ~ 1 的随机数。因为导入库的时候使用了 <code>import numpy as np</code> 命令，所有代码中可以用 <code>np</code> 来代替 <code>numpy</code>。</p>
<p><img src="https://file.shenfq.com/FjWSNNZ758iVgqaGunY3LNYu60Iv.png" alt="image"></p>
<p>上面就是通过 <code>numpy.random.rand</code> 方法生成一个 <code>3 * 3</code> 矩阵的案例。减去0.5是为了保证生成的权重所有权重都能维持在 -0.5 ~ 0.5 之间的一个随机值。</p>
<p><img src="https://file.shenfq.com/FuGnOobiInRSl4F9PXOP_Odn-YPj.png" alt="image"></p>
<p><strong>激活函数</strong></p>
<p><code>scipy.special</code> 模块中包含了大量的函数库，利用 <code>scipy.special</code> 库可以很方便快捷的构造出一个激活函数：</p>
<pre class="language-python"><code class="language-python">activation_function <span class="token operator">=</span> <span class="token keyword">lambda</span> x<span class="token punctuation">:</span> scipy<span class="token punctuation">.</span>special<span class="token punctuation">.</span>expit<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre>
<h4 id="%E6%9F%A5%E8%AF%A2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">查询神经网络<a class="anchor" href="#%E6%9F%A5%E8%AF%A2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">§</a></h4>
<pre class="language-python"><code class="language-python">    <span class="token comment"># 查询神经网络    </span>
    <span class="token keyword">def</span> <span class="token function">query</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将输入的数组转化为一个二维数组</span>
        inputs <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>inputs_list<span class="token punctuation">,</span> ndmin<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T
        
        <span class="token comment"># 计算输入数据与权重的点积</span>
        hidden_inputs <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>wih<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span>
        <span class="token comment"># 经过激活函数的到隐藏层数据</span>
        hidden_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>activation_function<span class="token punctuation">(</span>hidden_inputs<span class="token punctuation">)</span>
        
        <span class="token comment"># 计算隐藏层数据与权重的点积</span>
        final_inputs <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>who<span class="token punctuation">,</span> hidden_outputs<span class="token punctuation">)</span>
        <span class="token comment"># 最终到达输出层的数据</span>
        final_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>activation_function<span class="token punctuation">(</span>final_inputs<span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> final_outputs
</code></pre>
<p>查询神经网络的操作很简单，只需要使用 <code>numpy</code> 的 <code>dot</code> 方法对两个矩阵求点积即可。</p>
<p>这里有一个知识点，就是关于 <code>numpy</code> 的数据类型，通过 <code>numpy.array</code> 方法能够将 python 中的数组转为一个 N 维数组对象 <code>Ndarray</code>，该方法第二个参数就是表示转化后的维度。</p>
<p><img src="https://file.shenfq.com/FnfUXxYR0zUQaBWUxp8RNZXxBpbr.png" alt="image"></p>
<p>上图是一个普通数组 <code>[1, 2, 3]</code> 使用该方法转变成二维数组，返回 <code>[[1, 2, 3]]</code>。该方法还有个属性 T，本质是调用 <code>numpy</code> 的 <code>transpose</code> 方法，对数组进行轴对换，如下图所示。</p>
<p><img src="https://file.shenfq.com/FvmwZV-hOpFrG2uVrO3G-_nVgRCc.png" alt="image"></p>
<p>通过转置我们就能得到一个合适的输入矩阵了。</p>
<p><img src="https://file.shenfq.com/Fr4gSENAXsb-vwRuOkIc4OoIKT71.png" alt="image"></p>
<p><img src="https://file.shenfq.com/Fjz5HdsAs_XNskbCwoyB8Q0-4laj.png" alt="image"></p>
<h4 id="%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">训练神经网络<a class="anchor" href="#%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">§</a></h4>
<pre class="language-python"><code class="language-python">    <span class="token comment"># 训练神经网络</span>
    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs_list<span class="token punctuation">,</span> targets_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将输入数据与目标数据转为二维数组</span>
        inputs <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>inputs_list<span class="token punctuation">,</span> ndmin<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T
        targets <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>targets_list<span class="token punctuation">,</span> ndmin<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T
        
        <span class="token comment"># 通过矩阵点积和激活函数得到隐藏层的输出</span>
        hidden_inputs <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>wih<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span>
        hidden_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>activation_function<span class="token punctuation">(</span>hidden_inputs<span class="token punctuation">)</span>
        
        <span class="token comment"># 通过矩阵点积和激活函数得到最终输出</span>
        final_inputs <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>who<span class="token punctuation">,</span> hidden_outputs<span class="token punctuation">)</span>
        final_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>activation_function<span class="token punctuation">(</span>final_inputs<span class="token punctuation">)</span>
        
        <span class="token comment"># 获取目标值与实际值的差值</span>
        output_errors <span class="token operator">=</span> targets <span class="token operator">-</span> final_outputs
        <span class="token comment"># 反向传播差值</span>
        hidden_errors <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>who<span class="token punctuation">.</span>T<span class="token punctuation">,</span> output_errors<span class="token punctuation">)</span> 
        
        <span class="token comment"># 通过梯度下降法更新隐藏层到输出层的权重</span>
        self<span class="token punctuation">.</span>who <span class="token operator">+=</span> self<span class="token punctuation">.</span>lr <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>
            <span class="token punctuation">(</span>output_errors <span class="token operator">*</span> final_outputs <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> final_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
            np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>hidden_outputs<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        <span class="token comment"># 通过梯度下降法更新输入层到隐藏层的权重</span>
        self<span class="token punctuation">.</span>wih <span class="token operator">+=</span> self<span class="token punctuation">.</span>lr <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>
            <span class="token punctuation">(</span>hidden_errors <span class="token operator">*</span> hidden_outputs <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> hidden_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
            np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        
        <span class="token keyword">pass</span>
</code></pre>
<p>训练神经网络前半部分与查询类似，中间会将得到的差值通过求矩阵点积的方式进行反向传播，最后就是使用梯度下级的方法修正权重。其中 <code>self.lr</code> 为梯度下降的学习率，这个值是限制梯度方向的速率，我们需要经常调整这个值来达到模型的最优解。</p>
<h3 id="%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83">进行训练<a class="anchor" href="#%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83">§</a></h3>
<pre class="language-python"><code class="language-python"><span class="token comment"># 设置每一层的节点数量</span>
input_nodes <span class="token operator">=</span> <span class="token number">784</span>
hidden_nodes <span class="token operator">=</span> <span class="token number">100</span>
output_nodes <span class="token operator">=</span> <span class="token number">10</span>

<span class="token comment"># 学习率</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.1</span>

<span class="token comment"># 创建神经网络模型</span>
n <span class="token operator">=</span> neuralNetwork<span class="token punctuation">(</span>input_nodes<span class="token punctuation">,</span>hidden_nodes<span class="token punctuation">,</span>output_nodes<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span>

<span class="token comment"># 加载训练数据</span>
training_data_file <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"datasets/mnist_train_100.csv"</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>
training_data_list <span class="token operator">=</span> training_data_file<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
training_data_file<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 训练神经网络</span>
<span class="token comment"># epochs 表示训练次数</span>
epochs <span class="token operator">=</span> <span class="token number">10</span>
<span class="token keyword">for</span> e <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 遍历所有数据进行训练</span>
    <span class="token keyword">for</span> record <span class="token keyword">in</span> training_data_list<span class="token punctuation">:</span>
        <span class="token comment"># 数据通过 ',' 分割，变成一个数组</span>
        all_values <span class="token operator">=</span> record<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span>
        <span class="token comment"># 分离出图片的像素点到一个单独数组</span>
        inputs <span class="token operator">=</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>asfarray<span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span> <span class="token operator">*</span> <span class="token number">0.99</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.01</span>
        <span class="token comment"># 创建目标输出值（数字 0~9 出现的概率，默认全部为 0.01）</span>
        targets <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>output_nodes<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.01</span>
        <span class="token comment"># all_values[0] 表示手写数字的真实值，将该数字的概率设为 0.99</span>
        targets<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.99</span>
        n<span class="token punctuation">.</span>train<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>
        <span class="token keyword">pass</span>
    <span class="token keyword">pass</span>

<span class="token comment"># 训练完毕</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'done'</span><span class="token punctuation">)</span>

</code></pre>
<h3 id="%E9%AA%8C%E8%AF%81%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C">验证训练结果<a class="anchor" href="#%E9%AA%8C%E8%AF%81%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C">§</a></h3>
<pre class="language-python"><code class="language-python">
<span class="token comment"># 加载测试数据</span>
test_data_file <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"datasets/mnist_test_10.csv"</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>
test_data_list <span class="token operator">=</span> test_data_file<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
test_data_file<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 测试神经网络</span>
<span class="token comment"># 记录所有的训练值，正确存 1 ，错误存 0 。</span>
scorecard <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token comment"># 遍历所有数据进行测试</span>
<span class="token keyword">for</span> record <span class="token keyword">in</span> test_data_list<span class="token punctuation">:</span>
    <span class="token comment"># 数据通过 ',' 分割，变成一个数组</span>
    all_values <span class="token operator">=</span> record<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span>
    <span class="token comment"># 第一个数字为正确答案</span>
    correct_label <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># 取出测试的输入数据</span>
    inputs <span class="token operator">=</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>asfarray<span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span> <span class="token operator">*</span> <span class="token number">0.99</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.01</span>
    <span class="token comment"># 查询神经网络</span>
    outputs <span class="token operator">=</span> n<span class="token punctuation">.</span>query<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token comment"># 取出概率最大的数字，表示输出</span>
    label <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>outputs<span class="token punctuation">)</span>
    <span class="token comment"># 打印出真实值与查询值</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'act: '</span><span class="token punctuation">,</span> label<span class="token punctuation">,</span> <span class="token string">' pre: '</span><span class="token punctuation">,</span> correct_label<span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>label <span class="token operator">==</span> correct_label<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 神经网络查询结果与真实值匹配，记录数组存入 1</span>
        scorecard<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token comment"># 神经网络查询结果与真实值不匹配，记录数组存入 0</span>
        scorecard<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">pass</span>
    
    <span class="token keyword">pass</span>
    
<span class="token comment"># 计算训练的成功率</span>
scorecard_array <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>scorecard<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"performance = "</span><span class="token punctuation">,</span> scorecard_array<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> scorecard_array<span class="token punctuation">.</span>size<span class="token punctuation">)</span>
</code></pre>
<h3 id="%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81">完整代码<a class="anchor" href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81">§</a></h3>
<p>要查看完整代码可以访问我的 github： <a href="https://github.com/Shenfq/deep_neural_network/blob/master/NeuralNetWork.ipynb">deep_neural_network</a></p>
<h2 id="%E6%80%BB%E7%BB%93">总结<a class="anchor" href="#%E6%80%BB%E7%BB%93">§</a></h2>
<p>到这里整个深度神级网络的模型原理与实践已经全部进行完毕了，虽然有些部分概念讲解并不是那么仔细，但是你还可以通过搜索其他资料了解更多。感谢《Python神经网络编程》这本书，因为它才有了这个博客，如果感兴趣你也可以买来看看，这本书真的用很简单的语言描述了复杂的数学计算。</p>
<p>人工智能现在确实是一个非常火热的阶段，希望感兴趣的同学们多多尝试，但是也不要一昧的追新，忘记了自己本来的优势。</p></article></section><footer>Powered by <a href="https://github.com/xcatliu/pagic" target="_blank">Pagic</a></footer><script src="https://cdn.pagic.org/react@16.13.1/umd/react.production.min.js"></script><script src="https://cdn.pagic.org/react-dom@16.13.1/umd/react-dom.production.min.js"></script><script type="module" src="/docs/index.js"></script></body></html>